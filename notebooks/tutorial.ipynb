{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c70bf775-82ac-4c3c-a1b5-23af5ec8fb3f",
   "metadata": {},
   "source": [
    "CPH 08/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a58324c-8e7a-44ca-9f39-dc6563ce81b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MOCCA Tutorial\n",
    "\n",
    "MOCCA is a tool for the analysis of *High-Performance Liquid Chromatography–Diode Array Detection* (HPLC–DAD) datasets which are recorded in the context of reaction (process) controls. It only uses HPLC–DAD raw data and some basic user input which will be explained in this tutorial. For now, the program is only accessible to users with some basic Python skills and a Python environment up and running."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9c62ca-3119-472e-b873-efac56868581",
   "metadata": {},
   "source": [
    "## Installation and documentation\n",
    "\n",
    "For information on the installation, please visit MOCCA's GitHub repository (https://github.com/HaasCP/mocca) and documentation (https://mocca.readthedocs.io/en/latest/readme.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bcad8c-907f-45e8-b0a6-8bb1b4f61865",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff1b1321-02b7-4ffa-9bfd-76556f076ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folders handling\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# user interaction\n",
    "from mocca.user_interaction.campaign import HplcDadCampaign\n",
    "from mocca.user_interaction.user_objects import Gradient\n",
    "from mocca.user_interaction.user_objects import Compound\n",
    "from mocca.user_interaction.user_objects import InternalStandard\n",
    "from mocca.user_interaction.user_objects import HplcInput\n",
    "from mocca.user_interaction.settings import Settings\n",
    "from mocca.report.main import report\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d85391-6b55-4309-9bfa-ccb97e84b8f9",
   "metadata": {},
   "source": [
    "## Test data folder handling\n",
    "\n",
    "Some test data are added to the package in order to make this tutorial interactive. The test data can be found in the package in the folder mocca -> notebooks -> test_data. The data was recorded on an Agilent system (file extension .D)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa9e56ae-7937-44cb-939e-ebec3bf4ccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get path of this notebook\n",
    "ipynb_path = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "\n",
    "# add the path to the test data folder\n",
    "test_data_path = os.path.join(ipynb_path, \"tutorial_data\")\n",
    "\n",
    "# find all folders containing Agilent HPLC data (.D file extension)\n",
    "folders = glob(test_data_path + '/*' + '.D') \n",
    "folders = sorted(folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1945f4b-d9b9-42c0-9288-ee4c23181124",
   "metadata": {},
   "source": [
    "We added four paths to the folders variable, which are two gradients (more detail why **two** gradients [below](#gradient_handling)) and two samples containing the same analyte (second only half the concentration). In the following, we want to use the first analyte run to \"train\" the tool and to subsequently analyze the second run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36a5d434-f4d2-46bb-acd1-4a7d484dbd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-26_19-37-57_gradient.D\n",
      "2022-01-26_19-43-27_gradient.D\n",
      "2022-01-26_19-48-52_ba_1.D\n",
      "2022-01-26_20-00-51_ba_0.5.D\n"
     ]
    }
   ],
   "source": [
    "for folder in folders:\n",
    "    print(os.path.basename(folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c32666c-1ea8-4ad6-85d8-e0b581f5f044",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Basic user interaction\n",
    "\n",
    "The tool uses multiple HPLC–DAD datasets for contextual analysis. These datasets are stored and processed in so called HPLC–DAD campaigns, which later on also contain results of the analysis. You can initialize HplcDadCampaign objects as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe39984f-a98f-42ff-be08-4f90e4014d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "camp = HplcDadCampaign()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04d3288-7d54-4501-b453-3edb5f323906",
   "metadata": {},
   "source": [
    "You can add HPLC–DAD chromatograms to the campaign using HplcInput objects. For any HplcInput object, at least a path to the actual data has to be given as well as a corresponding gradient run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be63e5f5-97c6-4b89-b0d3-0e3ee7878ce5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Gradient handling <a id='gradient_handling'></a>\n",
    "\n",
    "Instead of a baseline correction routine for each individual HPLC–DAD chromatogram, MOCCA requires the data of a pre-recorded gradient run which is baseline-corrected and subsequently subtracted from the following HPLC–DAD chromatogram. A Gradient object in MOCCA only requires the path to the gradient data.\n",
    "\n",
    "**Experimental note**: In order to obtain a most representative gradient run for the following data, you should run a \"dummy\" gradient first and subsequently a second gradient in the fashion, your reaction control takes place. For example, if you run methods of 5 minutes without a pause of 2 minutes in between runs, you should use gradient data which was recorded after the required 5 minutes method and a 2 minutes pause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af8e9c70-2cac-425e-ade6-e017622f3206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the second gradient folder\n",
    "test_gradient = Gradient(folders[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8207f2-8fe2-4ba9-9b67-d7f917c9f3ed",
   "metadata": {},
   "source": [
    "At this point, the gradient run is not yet processed. For now, only the path is stored in the object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116932b5-1619-4ad1-a186-e5f498bc934b",
   "metadata": {},
   "source": [
    "### Compound objects: How to train the tool <a id='compound'></a>\n",
    "\n",
    "You can \"train\" the tool through Compound objects and analyte HPLC runs. For that, you should have a pure sample of your analyte you want the tool to be trained on. The biggest (by integral) unknown peak in the given data is considered as the given compound by the tool during the data processing.\n",
    "\n",
    "Compounds **must** contain a key, i.e., a unique identifier as a string and **can** contain a concentration. In the first case, the compound will only be used for peak assignment tasks while adding a concentration leads to the creation of calibration curves and quantification of peaks in analysis runs.\n",
    "\n",
    "Moreover, the user can give the tool information if the given compound is an internal standard (which will be used for retention time correction and relative quantification onwards). This information is required by the tool to process the chromatograms in corresponding order and to function properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ea66829-cc03-476e-b56b-c4dcb578accd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# internal standard component\n",
    "test_istd_compound = Compound(\"istd_name\", is_istd=True)\n",
    "\n",
    "# compound for peak assignment only\n",
    "test_compound = Compound(\"benzaldehyde\")\n",
    "\n",
    "# compound for retention time correction and quantification\n",
    "test_compound_conc = Compound(\"benzaldehyde\", conc=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec698adf-6166-4012-9f9b-dce6dd5f97fb",
   "metadata": {},
   "source": [
    "### Internal standards\n",
    "\n",
    "The tool can automatically handle internal standards if this information is given by the user. The tool can only handle known internal standards, i.e., internal standards which the tool was already trained on by the [compound method](#compound) (see test_istd_compound). For such internal standards, you can add InternalStandard objects which the tool uses to correct retention times and to quantify relatively to the internal standard signal (only if a internal standard concentration is given).\n",
    "\n",
    "For an example of the usage of internal standards in experimental reaction controls, see in the cyanation.ipynb notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7aadfd26-38e5-4b47-9e73-4eea1d90d874",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_istd_0 = InternalStandard(\"istd_name\")\n",
    "test_istd_1 = InternalStandard(\"istd_name\", conc=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf39704-86d4-436b-a822-ac7bae77bf9b",
   "metadata": {},
   "source": [
    "### HPLC input\n",
    "\n",
    "All above-mentioned user input is bundled into an HplcInput object. This object **must** contain a path to the data and a gradient. It **can** contain a compound and/or an internal standard. HplcInput objects without compound will be analyzed while HplcInput object with compound input are used to train the tool.\n",
    "\n",
    "For our test data, we create one HplcInput object to train the tool and one HplcObject which will be analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4d8ab1c-7b53-4646-a0a8-72a3b455fa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "init_folder = folders[2]\n",
    "init_input = HplcInput(init_folder, test_gradient, compound=test_compound_conc)\n",
    "\n",
    "# test data\n",
    "analyze_folder = folders[3]\n",
    "analyze_input =  HplcInput(analyze_folder, test_gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec3bafb-e48a-4625-ae04-9e97878f5b3b",
   "metadata": {},
   "source": [
    "To add these HplcInput objects to the campaign, you can use the add_hplc_input function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb62699a-6e6b-4476-8a41-bcf1aa90277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "camp.add_hplc_input(init_input)\n",
    "camp.add_hplc_input(analyze_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a70e0f-4b65-4f64-a2b2-051f1ae58247",
   "metadata": {},
   "source": [
    "### Settings for data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb9f85c-cf2a-4cfd-b525-2dd48bbd189e",
   "metadata": {},
   "source": [
    "The campaign has now all the user input required to process the HPLC–DAD data. However, you have control over various processing parameters via the Settings object. The Settings object has some default values which may deliver satisfying results, however, often it is necessary to adjust some values in order to get correct results. The settings parameters are:\n",
    "\n",
    "**hplc_system_tag**, required: A string indicating which HPLC system was used and from which software the data was exported. So far implemented are \"chemstation\" for Agilent HPLC systems, \"labsolutions\" for Shimadzu HPLC systems, \"empower\" for Waters HPLC systems, and \"allotrope\" for ADF data. See scientific publication for more details.\n",
    "\n",
    "**detector_limit**, optional: A absorbance value which triggers saturation warnings in case it is exceeded in a peak. Default value is infinity.\n",
    "\n",
    "**absorbance_threshold**, optional: A sensitivity measure which defines 1. the summed (over all wavelengths) absorbance value a peak has to exceeed at its maximum to be recognized as a peak, 2. the height of the baseline to which peaks are expanded which is one twentieths of the value. Default value is 500.\n",
    "\n",
    "**wl_high_pass** and **wl_low_pass**, optional: Constricts the wavelengths which are used for data processing so that for all valid wavelengths wl applies wl_high_pass <= wl <= wl_low_pass. Default value is None for both (no constriction).\n",
    "\n",
    "**peaks_high_pass** and **peak_low_pass**, optional: Constricts the retention time domain in which peaks are processed so that for all valid peak maxima peak_max applies peaks_high_pass <= peak_max <= peak_low_pass. Default value is None for both (no constriction).\n",
    "\n",
    "**spectrum_correl_thresh**, optional: Correlation coefficient of two UV-Vis spectra has to exceed this threshold value in order to be a potential match. Default value is 0.95.\n",
    "\n",
    "**relative_distance_thresh**, optional: The time difference between two peaks (relative to the total chromatogram time) has to be below this threshold value in order to be considered as potential match. Defaul value is 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3e8aea8-f5c8-45e4-bb75-e3d19d50befc",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = Settings('chemstation',\n",
    "                    absorbance_threshold = 300, wl_high_pass = 215, \n",
    "                    peaks_high_pass = 1, peaks_low_pass = 3.2,\n",
    "                    spectrum_correl_thresh=0.99, relative_distance_thresh=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926a0b31-e525-4574-8cea-38e39ca6b203",
   "metadata": {},
   "source": [
    "### Data processing\n",
    "\n",
    "You can process the data by adding the above defined settings to the process_all_hplc_input function. Note, that you **must** provide at least a Settings object with an hplc_system_tag given. In this example, an expected warning is given, that R^2 scores in linear regressions are not well-defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7e53c99-166e-4fa6-a5ff-700216a1729c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haascp/opt/anaconda3/envs/test/lib/python3.9/site-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    }
   ],
   "source": [
    "camp.process_all_hplc_input(settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876d7ceb-7e66-4050-9569-ff4c97f25e40",
   "metadata": {},
   "source": [
    "## Result reporting\n",
    "\n",
    "Results are provided to the user in form of reports. For more information, see the SI of the scientific publication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edb947f0-278c-40ee-8347-b1efd5d9c35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder before creating reports\n",
    "test_report_path = os.path.join(ipynb_path, \"tutorial_reports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c15f8fa-57e0-489f-bbcc-610cb4dc55f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Report saved to .//Users/haascp/Documents/GitHub/mocca/notebooks/tutorial_reports/hplc_input.html. To upload and share your report, create a free Datapane account by running `!datapane signup`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Report saved to .//Users/haascp/Documents/GitHub/mocca/notebooks/tutorial_reports/gradient.html. To upload and share your report, create a free Datapane account by running `!datapane signup`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Report saved to .//Users/haascp/Documents/GitHub/mocca/notebooks/tutorial_reports/peak_library.html. To upload and share your report, create a free Datapane account by running `!datapane signup`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Report saved to .//Users/haascp/Documents/GitHub/mocca/notebooks/tutorial_reports/chromatograms.html. To upload and share your report, create a free Datapane account by running `!datapane signup`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No chromatograms given or all chromatograms are good data!\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Report saved to .//Users/haascp/Documents/GitHub/mocca/notebooks/tutorial_reports/compound_tracking.html. To upload and share your report, create a free Datapane account by running `!datapane signup`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No PARAFAC models were found in the given datasets.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Report saved to .//Users/haascp/Documents/GitHub/mocca/notebooks/tutorial_reports/compound_library.html. To upload and share your report, create a free Datapane account by running `!datapane signup`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Report saved to .//Users/haascp/Documents/GitHub/mocca/notebooks/tutorial_reports/calibration_library.html. To upload and share your report, create a free Datapane account by running `!datapane signup`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "How is your experience of Datapane? Please take two minutes to answer our anonymous product survey <a href='https://bit.ly/3lWjRlr' target='_blank'>here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "report(camp, test_report_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21863ee2-43dc-49d1-bea5-258fc615f381",
   "metadata": {},
   "source": [
    "## Save and load HplcDadCampaign objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5b3458-aed8-4f64-88fd-d3e6f59d6ed0",
   "metadata": {},
   "source": [
    "You can save the campaign object as a .pkl-file so that the campaign object can be reused without letting the processing run again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db78b59c-550e-4a3a-8706-60a9358cda5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the campaign is saved within the notebook folder or alternatively to a given path\n",
    "camp.save_campaign(os.path.join(ipynb_path, 'camp.pkl'), remove_raw_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a3e4ff-dc94-49fe-9269-0064079205b2",
   "metadata": {},
   "source": [
    "If you want to load an existing campaign saved as a .pkl-file you have to create an HplcDadCampaign object and load the campaign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ffb6a00-56e1-49fe-a3de-b3174494d816",
   "metadata": {},
   "outputs": [],
   "source": [
    "camp = HplcDadCampaign()\n",
    "# Enter path to .pkl file\n",
    "pkl_path = os.path.join(ipynb_path, 'camp.pkl')\n",
    "camp.load_campaign(pkl_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e1b285-98fa-45ef-9808-a3dd9f89931d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Results extraction in Python environment\n",
    "\n",
    "In the following sections, all relevant data are presented in the Pythonic form, i.e., in which object the information is stored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bba460-0c7f-4b3d-9285-6f4a16ebccc7",
   "metadata": {},
   "source": [
    "### User input\n",
    "\n",
    "Let's first look at the stored user input and the corresponding report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38f9dbe9-af68-4c38-ae13-207d106aa0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HplcInput(path='/Users/haascp/Documents/GitHub/mocca/notebooks/tutorial_data/2022-01-26_19-48-52_ba_1.D', gradient=Gradient(/Users/haascp/Documents/GitHub/mocca/notebooks/tutorial_data/2022-01-26_19-43-27_gradient.D), compound=Compound(key='benzaldehyde', conc=1, is_solvent=False, is_istd=False), istd=None, processed=True, custom_data=None), HplcInput(path='/Users/haascp/Documents/GitHub/mocca/notebooks/tutorial_data/2022-01-26_20-00-51_ba_0.5.D', gradient=Gradient(/Users/haascp/Documents/GitHub/mocca/notebooks/tutorial_data/2022-01-26_19-43-27_gradient.D), compound=None, istd=None, processed=True, custom_data=None)]\n"
     ]
    }
   ],
   "source": [
    "# where to find in environment\n",
    "print(camp.hplc_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e514f1-1e3b-4e8a-97ab-9274bb4a094f",
   "metadata": {},
   "source": [
    "### Gradients\n",
    "\n",
    "Gradient objects can be found as attributes in the above mentioned HplcInput objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f2d8cb-caf0-4d64-a518-5359643a495b",
   "metadata": {},
   "source": [
    "### Chromatograms\n",
    "\n",
    "This is the main results source which you find in the chroms attribute of the campaign. The chromatograms have several attributes like experiment (the HPLC input), peaks (all picked and processed peaks of the chromatogram), dataset (the HPLC–DAD raw data object) and a boolean value in bad_data which indicates if the analysis has found some critical problem with the dataset (e.g. the user gives an internal standard but the corrsponding peak was not found)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24146dc7-b12a-4b13-b2cd-f31074509946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chroms attribute:\n",
      "[<mocca.chromatogram.model.Chromatogram object at 0x13fea20a0>, <mocca.chromatogram.model.Chromatogram object at 0x13fea2e20>]\n",
      "\n",
      "User input for the chrom:\n",
      "HplcInput(path='/Users/haascp/Documents/GitHub/mocca/notebooks/tutorial_data/2022-01-26_19-48-52_ba_1.D', gradient=Gradient(/Users/haascp/Documents/GitHub/mocca/notebooks/tutorial_data/2022-01-26_19-43-27_gradient.D), compound=Compound(key='benzaldehyde', conc=1, is_solvent=False, is_istd=False), istd=None, processed=True, custom_data=None)\n",
      "\n",
      "Found peaks:\n",
      "[ProcessedPeak(left=1360, right=1399, maximum=1374, offset=0, dataset=<class 'mocca.dad_data.models.CompoundData'>, idx=1, saturation=False, pure=True, integral=9543.834340669906, istd=[], compound_id='benzaldehyde_impurity_1', concentration=None, is_compound=False), ProcessedPeak(left=1437, right=1521, maximum=1471, offset=0, dataset=<class 'mocca.dad_data.models.CompoundData'>, idx=2, saturation=False, pure=True, integral=260967.44102498665, istd=[], compound_id='benzaldehyde', concentration=1, is_compound=True)]\n",
      "\n",
      "Dataset:\n",
      "CompoundData(hplc_system_tag='chemstation', path='/Users/haascp/Documents/GitHub/mocca/notebooks/tutorial_data/2022-01-26_19-48-52_ba_1.D', data=array([[-1.37719602e+00, -1.34173408e+00, -1.25293882e+00, ...,\n",
      "         2.96112510e+00,  3.05941358e+00,  3.30436780e+00],\n",
      "       [-1.31121424e+00, -1.24186012e+00, -1.18583934e+00, ...,\n",
      "         3.21473227e+00,  3.22471678e+00,  3.38136696e+00],\n",
      "       [-1.01989447e+00, -9.50662806e-01, -8.61431152e-01, ...,\n",
      "         3.51669975e+00,  3.57371566e+00,  3.81073049e+00],\n",
      "       ...,\n",
      "       [-1.55064475e-02,  1.80091400e-02,  4.85805505e-03, ...,\n",
      "        -2.75406104e-02, -4.73490170e-02, -5.38241202e-02],\n",
      "       [-3.76238333e-02, -3.76443072e-02, -1.76647913e-02, ...,\n",
      "         3.66340685e-03,  5.01303544e-02,  9.93074021e-03],\n",
      "       [ 7.18502180e-02,  1.38259622e-01,  1.58002354e-01, ...,\n",
      "        -4.02339693e-03, -5.69526690e-02,  3.45104502e-03]]), time=array([1.59883721e-03, 3.19767442e-03, 4.79651163e-03, ...,\n",
      "       3.98430233e+00, 3.98590116e+00, 3.98750000e+00]), wavelength=array([215., 216., 217., 218., 219., 220., 221., 222., 223., 224., 225.,\n",
      "       226., 227., 228., 229., 230., 231., 232., 233., 234., 235., 236.,\n",
      "       237., 238., 239., 240., 241., 242., 243., 244., 245., 246., 247.,\n",
      "       248., 249., 250., 251., 252., 253., 254., 255., 256., 257., 258.,\n",
      "       259., 260., 261., 262., 263., 264., 265., 266., 267., 268., 269.,\n",
      "       270., 271., 272., 273., 274., 275., 276., 277., 278., 279., 280.,\n",
      "       281., 282., 283., 284., 285., 286., 287., 288., 289., 290., 291.,\n",
      "       292., 293., 294., 295., 296., 297., 298., 299., 300., 301., 302.,\n",
      "       303., 304., 305., 306., 307., 308., 309., 310., 311., 312., 313.,\n",
      "       314., 315., 316., 317., 318., 319., 320., 321., 322., 323., 324.,\n",
      "       325., 326., 327., 328., 329., 330., 331., 332., 333., 334., 335.,\n",
      "       336., 337., 338., 339., 340., 341., 342., 343., 344., 345., 346.,\n",
      "       347., 348., 349., 350., 351., 352., 353., 354., 355., 356., 357.,\n",
      "       358., 359., 360., 361., 362., 363., 364., 365., 366., 367., 368.,\n",
      "       369., 370., 371., 372., 373., 374., 375., 376., 377., 378., 379.,\n",
      "       380., 381., 382., 383., 384., 385., 386., 387., 388., 389., 390.,\n",
      "       391., 392., 393., 394., 395., 396., 397., 398., 399., 400., 401.,\n",
      "       402., 403., 404., 405., 406., 407., 408., 409., 410., 411., 412.,\n",
      "       413., 414., 415., 416., 417., 418., 419., 420., 421., 422., 423.,\n",
      "       424., 425., 426., 427., 428., 429., 430., 431., 432., 433., 434.,\n",
      "       435., 436., 437., 438., 439., 440., 441., 442., 443., 444., 445.,\n",
      "       446., 447., 448., 449.]), warnings=[])\n",
      "\n",
      "Bad Data:\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# where to find in environment\n",
    "print(f\"Chroms attribute:\\n{camp.chroms}\\n\")\n",
    "print(f\"User input for the chrom:\\n{camp.chroms[0].experiment}\\n\")  # hplc_input is labelled \"experiment\" in the backend\n",
    "print(f\"Found peaks:\\n{camp.chroms[0].peaks}\\n\")\n",
    "print(f\"Dataset:\\n{camp.chroms[0].dataset}\\n\")\n",
    "print(f\"Bad Data:\\n{camp.chroms[0].bad_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3e7126-e48e-4cd5-b097-27b2754fd382",
   "metadata": {},
   "source": [
    "### Peak database\n",
    "\n",
    "In this attribute, all processed peaks of all chromatograms in the campaign are stored. This database is used to create the qualitative and the quantitative component databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "300c86a3-a527-4e5b-a8c8-19169637e1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database object:\n",
      "<mocca.peak.database.PeakDatabase object at 0x13db14220>\n",
      "\n",
      "Database entries (peaks):\n",
      "ProcessedPeak(left=1437, right=1521, maximum=1471, offset=0, dataset=<class 'mocca.dad_data.models.CompoundData'>, idx=2, saturation=False, pure=True, integral=260967.44102498665, istd=[], compound_id='benzaldehyde', concentration=1, is_compound=True)\n",
      "ProcessedPeak(left=1360, right=1399, maximum=1374, offset=0, dataset=<class 'mocca.dad_data.models.CompoundData'>, idx=1, saturation=False, pure=True, integral=9543.834340669906, istd=[], compound_id='benzaldehyde_impurity_1', concentration=None, is_compound=False)\n",
      "ProcessedPeak(left=1448, right=1524, maximum=1472, offset=0, dataset=<class 'mocca.dad_data.models.CompoundData'>, idx=1, saturation=False, pure=True, integral=140531.50647044505, istd=[], compound_id='benzaldehyde', concentration=0.5220528115580517, is_compound=False)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Database object:\\n{camp.peak_db}\\n\")\n",
    "\n",
    "print(\"Database entries (peaks):\")\n",
    "for peak in camp.peak_db:\n",
    "    print(peak)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187fff2f-6b85-4707-96d8-137cbcd9887f",
   "metadata": {},
   "source": [
    "### Qualitative component database\n",
    "\n",
    "In this database, the components (created from the signals of the same compound over multiple chromatograms) contain the information needed for peak assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c069c40e-915a-407a-9b85-ff8c76511c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database object:\n",
      "<mocca.components.databases.QualiComponentDatabase object at 0x13fea2bb0>\n",
      "\n",
      "Database entries (qualitative components):\n",
      "QualiComponent(compound_id='benzaldehyde', left=1442, right=1522, maximum=1472, offset=0, spectrum=<class 'list'>, spectrum_max=[32, 67], created_from=[ProcessedPeak(left=1437, right=1521, maximum=1471, offset=0, dataset=<class 'mocca.dad_data.models.CompoundData'>, idx=2, saturation=False, pure=True, integral=260967.44102498665, istd=[], compound_id='benzaldehyde', concentration=1, is_compound=True)])\n",
      "QualiComponent(compound_id='benzaldehyde_impurity_1', left=1360, right=1399, maximum=1374, offset=0, spectrum=<class 'list'>, spectrum_max=[14, 36, 59, 57, 55, 61, 46, 66, 48, 44, 53, 40, 51], created_from=[ProcessedPeak(left=1360, right=1399, maximum=1374, offset=0, dataset=<class 'mocca.dad_data.models.CompoundData'>, idx=1, saturation=False, pure=True, integral=9543.834340669906, istd=[], compound_id='benzaldehyde_impurity_1', concentration=None, is_compound=False)])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Database object:\\n{camp.quali_comp_db}\\n\")\n",
    "\n",
    "print(\"Database entries (qualitative components):\")\n",
    "for comp in camp.quali_comp_db:\n",
    "    print(comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa99cd1-4007-44de-8dc3-4dce061eace7",
   "metadata": {},
   "source": [
    "### Quantitative component database\n",
    "\n",
    "In this database, the components (created from the signals of the same compound over multiple chromatograms) contain the information needed for peak quantification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb2de703-b8f4-4f6b-9228-483fc0aa5b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database object:\n",
      "<mocca.components.databases.QuantComponentDatabase object at 0x13fea2340>\n",
      "\n",
      "Database entries (quantitative components):\n",
      "QuantComponent(compound_id='benzaldehyde', integrate_wl_idx=32, calib_factors={'absolute': 8241.430639717715}, calib_data={'absolute': [(1, 8241.430639717715)]}, calib_scores={'absolute': nan}, created_from=[ProcessedPeak(left=1437, right=1521, maximum=1471, offset=0, dataset=<class 'mocca.dad_data.models.CompoundData'>, idx=2, saturation=False, pure=True, integral=260967.44102498665, istd=[], compound_id='benzaldehyde', concentration=1, is_compound=True)])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Database object:\\n{camp.quant_comp_db}\\n\")\n",
    "\n",
    "print(\"Database entries (quantitative components):\")\n",
    "for comp in camp.quant_comp_db:\n",
    "    print(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bba3a99-0966-44a5-92f1-80c3d159e72e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
