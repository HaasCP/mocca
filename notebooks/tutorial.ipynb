{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c70bf775-82ac-4c3c-a1b5-23af5ec8fb3f",
   "metadata": {},
   "source": [
    "CPH 02/03/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a58324c-8e7a-44ca-9f39-dc6563ce81b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Multivariate Online Chromatographic Contextual Analysis (MOCCA) Tutorial\n",
    "\n",
    "MOCCA is a tool for the analysis of *High-Performance Liquid Chromatography–Diode Array Detection* (HPLC–DAD) datasets which are recorded in the context of reaction (process) controls. It only uses HPLC–DAD raw data and some basic user input which will be explained in this tutorial. For now, the program is only accessible to users with some basic Python skills and a Python environment up and running."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9c62ca-3119-472e-b873-efac56868581",
   "metadata": {},
   "source": [
    "## Installation (pre-publishing)\n",
    "\n",
    "For the installation of the package, use terminal (or conda cmd.exe) to change directory (cd) into the mocca folder. You can interact with it from the command line after creating (or activating) an isolated development environment (with virtualenv, conda or your preferred tool). To install the package, perform the an editable install:\n",
    "\n",
    "`pip install -e mocca`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bcad8c-907f-45e8-b0a6-8bb1b4f61865",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff1b1321-02b7-4ffa-9bfd-76556f076ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folders handling\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# user interaction\n",
    "from mocca.user_interaction.campaign import HplcDadCampaign\n",
    "from mocca.user_interaction.user_objects import Gradient\n",
    "from mocca.user_interaction.user_objects import Compound\n",
    "from mocca.user_interaction.user_objects import InternalStandard\n",
    "from mocca.user_interaction.user_objects import HplcInput\n",
    "from mocca.user_interaction.settings import Settings\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d85391-6b55-4309-9bfa-ccb97e84b8f9",
   "metadata": {},
   "source": [
    "## Test data folder handling\n",
    "\n",
    "Some test data are added to the package in order to make this tutorial interactive. The test data can be found in the package in the folder mocca -> notebooks -> test_data. The data was recorded on an Agilent system. For Agilent HPLC–DAD data obtained using the 3D-export macro, the folders containing the DAD*n*.csv files must be given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa9e56ae-7937-44cb-939e-ebec3bf4ccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get path of this notebook\n",
    "ipynb_path = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "\n",
    "# add the path to the test data folder\n",
    "test_data_path = os.path.join(ipynb_path, \"tutorial_data\")\n",
    "\n",
    "# find all folders containing Agilent HPLC data (.D file extension)\n",
    "folders = glob(test_data_path + '/*' + '.D') \n",
    "folders = sorted(folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1945f4b-d9b9-42c0-9288-ee4c23181124",
   "metadata": {},
   "source": [
    "We added four paths to the folders variable, which are two gradients (more detail why **two** gradients [below](#gradient_handling)) and two samples containing the same analyte (second only half the concentration). In the following, we want to use the first analyte run to \"train\" the tool and to subsequently analyze "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36a5d434-f4d2-46bb-acd1-4a7d484dbd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-26_19-37-57_gradient.D\n",
      "2022-01-26_19-43-27_gradient.D\n",
      "2022-01-26_19-48-52_ba_1.D\n",
      "2022-01-26_20-00-51_ba_0.5.D\n"
     ]
    }
   ],
   "source": [
    "for folder in folders:\n",
    "    print(os.path.basename(folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c32666c-1ea8-4ad6-85d8-e0b581f5f044",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Basic user interaction\n",
    "\n",
    "The tool uses datasets composed of multiple chromatograms to analyze HPLC–DAD data. These datasets are stored and processed in so called HPLC–DAD campaigns, which later on also contain results of the analysis. You can initialize HplcDadCampaign objects as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe39984f-a98f-42ff-be08-4f90e4014d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "camp = HplcDadCampaign()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04d3288-7d54-4501-b453-3edb5f323906",
   "metadata": {},
   "source": [
    "You can add HPLC–DAD chromatograms to the campaign using HplcInput objects. For any HplcInput object, at least a path to the actual data has to be given as well as a corresponding gradient run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be63e5f5-97c6-4b89-b0d3-0e3ee7878ce5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Gradient handling <a id='gradient_handling'></a>\n",
    "\n",
    "Instead of a baseline correction routine for each individual HPLC–DAD chromatogram, mocca requires the data of a pre-recorded gradient run which is baseline-corrected and subsequently subtracted from all following HPLC–DAD chromatograms. A Gradient object in mocca only requires the path to the gradient data.\n",
    "\n",
    "**Experimental note**: In order to obtain a most representative gradient run for the following data, you should run a \"dummy\" gradient first and subsequently a second gradient in the fashion, your reaction control takes place. For example, if you run methods of 5 minutes without a pause of 2 minutes in between runs, you should use gradient data which was recorded after the required 5 minutes method and a 2 minutes pause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af8e9c70-2cac-425e-ade6-e017622f3206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the second gradient folder\n",
    "test_gradient = Gradient(folders[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8207f2-8fe2-4ba9-9b67-d7f917c9f3ed",
   "metadata": {},
   "source": [
    "At this point, the gradient run is not yet processed. For now, only the path is stored in the object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116932b5-1619-4ad1-a186-e5f498bc934b",
   "metadata": {},
   "source": [
    "### Compound objects: How to train the tool <a id='compound'></a>\n",
    "\n",
    "You can \"train\" the tool through Compound objects and analyte HPLC runs. For that, you should have a pure sample of your analyte you want the tool to be trained on. The biggest (by integral) unknown peak in the given data is considered as the given compound by the tool during the data processing.\n",
    "\n",
    "Compounds **must** contain a key, i.e., a unique identifier as a string and **can** contain a concentration. In the first case, the compound will only be used for peak assignment tasks while adding a concentration leads to the creation of calibration curves and quantification of peaks in reaction runs.\n",
    "\n",
    "Moreover, the user can give the tool the information if the given compound is a solvent (which will be found in all other chromatograms) or an internal standard (which will be used for retention time correction and relative quantification onwards). This information is required by the tool to process the chromatograms in corresponding order and to function properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ea66829-cc03-476e-b56b-c4dcb578accd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solvent component\n",
    "test_solvent_compound = Compound(\"solvent_name\", is_solvent=True)\n",
    "\n",
    "# internal standard component\n",
    "test_istd_compound = Compound(\"istd_name\", is_istd=True)\n",
    "\n",
    "# compound for peak assignment only\n",
    "test_compound = Compound(\"benzaldehyde\")\n",
    "\n",
    "# compound for retention time correction and quantification\n",
    "test_compound_conc = Compound(\"benzaldehyde\", conc=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec698adf-6166-4012-9f9b-dce6dd5f97fb",
   "metadata": {},
   "source": [
    "### Internal standards\n",
    "\n",
    "The tool can automatically handle internal standards if this information is given by the user. The tool can only handle known internal standards, i.e., internal standards which the tool was already trained on by the [compound method](#compound) (see test_istd_compound). For such internal standards, you can add InternalStandard objects which the tool uses to correct retention times and to quantify relatively to the internal standard signal (only if a internal standard concentration is given)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7aadfd26-38e5-4b47-9e73-4eea1d90d874",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_istd_0 = InternalStandard(\"istd_name\")\n",
    "test_istd_1 = InternalStandard(\"istd_name\", conc=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf39704-86d4-436b-a822-ac7bae77bf9b",
   "metadata": {},
   "source": [
    "### HPLC input\n",
    "\n",
    "All above-mentioned user input is bundled into an HplcInput object. This object **must** contain a path to the data and a gradient. It **can** contain a compound and/or an internal standard. HplcInput objects without compound will be analyzed while HplcInput object with compound input are used to train the tool.\n",
    "\n",
    "For our test data, we create one HplcInput object to train the tool and one HplcObject which will be analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4d8ab1c-7b53-4646-a0a8-72a3b455fa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "init_folder = folders[2]\n",
    "init_input = HplcInput(init_folder, test_gradient, test_compound_conc)\n",
    "\n",
    "# test data\n",
    "analyze_folder = folders[3]\n",
    "analyze_input =  HplcInput(analyze_folder, test_gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec3bafb-e48a-4625-ae04-9e97878f5b3b",
   "metadata": {},
   "source": [
    "To add these HplcInput objects to the campaign, you can use the add_hplc_input function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb62699a-6e6b-4476-8a41-bcf1aa90277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "camp.add_hplc_input(init_input)\n",
    "camp.add_hplc_input(analyze_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a70e0f-4b65-4f64-a2b2-051f1ae58247",
   "metadata": {},
   "source": [
    "### Settings for data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb9f85c-cf2a-4cfd-b525-2dd48bbd189e",
   "metadata": {},
   "source": [
    "The campaign has now all the user input required to process the HPLC–DAD data. However, you have control over various processing parameters via the Settings object. The Settings object has some default values which may deliver satisfying results, however, often it is necessary to adjust some values in order to get correct results. The settings parameters are:\n",
    "\n",
    "**hplc_system_tag**, required: A string indicating which HPLC system was used and from which software the data was exported. So far implemented are \"chemstation\" for Agilent HPLC systems and \"labsolutions\" for Shimadzu HPLC systems.\n",
    "\n",
    "**detector_limit**, optional: A absorbance value which triggers saturation warnings in case it is exceeded in a peak. Default values are 2000 if hplc_system_tag is \"chemstation\" and 2000 if hplc_system_tag is \"labsolutions\".\n",
    "\n",
    "**absorbance_threshold**, optional: A sensitivity measure which defines 1. the summed (over all wavelengths) absorbance value a peak has to exceeed at its maximum to be recognized as a peak, 2. the height of the baseline to which peaks are expanded which is one twentieths of the value. Default value is 500.\n",
    "\n",
    "**wl_high_pass** and **wl_low_pass**, optional: Constricts the wavelengths which are used for data processing so that for all valid wavelengths wl applies wl_high_pass <= wl <= wl_low_pass. Default value is None for both (no constriction).\n",
    "\n",
    "**peaks_high_pass** and **peak_low_pass**, optional: Constricts the retention time domain in which peaks are processed so that for all valid peak maxima peak_max applies peaks_high_pass <= peak_max <= peak_low_pass. Default value is None for both (no constriction).\n",
    "\n",
    "**spectrum_correl_thresh**, optional: Correlation coefficient of two UV-Vis spectra has to exceed this threshold value in order to be a potential match. Default value is 0.95.\n",
    "\n",
    "**relative_distance_thresh**, optional: The time difference between two peaks (relative to the total chromatogram time) has to be below this threshold value in order to be considered as potential match. Defaul value is 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3e8aea8-f5c8-45e4-bb75-e3d19d50befc",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = Settings('chemstation',\n",
    "                    absorbance_threshold = 300, wl_high_pass = 215, \n",
    "                    peaks_high_pass = 1, peaks_low_pass = 3.2,\n",
    "                    spectrum_correl_thresh=0.99, relative_distance_thresh=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926a0b31-e525-4574-8cea-38e39ca6b203",
   "metadata": {},
   "source": [
    "### Data processing\n",
    "\n",
    "You can process the data by adding the above defined settings to the process_all_hplc_input function. Note, that you **must** provide at least a Settings object with an hplc_system_tag given. In this example, an expected warning is given, that R^2 scores in linear regressions are not well-defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7e53c99-166e-4fa6-a5ff-700216a1729c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haascp/opt/anaconda3/envs/mocca-dev/lib/python3.9/site-packages/sklearn/metrics/_regression.py:781: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    }
   ],
   "source": [
    "camp.process_all_hplc_input(settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876d7ceb-7e66-4050-9569-ff4c97f25e40",
   "metadata": {},
   "source": [
    "## Result reporting\n",
    "\n",
    "The reporting will be reworked on the fly during alpha and beta version rollout. A full set of reports is generated by the generate_reports of the HplcDadCampaign object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edb947f0-278c-40ee-8347-b1efd5d9c35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_report_path = os.path.join(ipynb_path, \"tutorial_reports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c15f8fa-57e0-489f-bbcc-610cb4dc55f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Report saved to .//Users/haascp/Documents/GitHub/mocca/notebooks/tutorial_reports/report_hplc_input.html. To upload and share your report, create a free Datapane account by running `!datapane signup`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Report saved to .//Users/haascp/Documents/GitHub/mocca/notebooks/tutorial_reports/report_gradient.html. To upload and share your report, create a free Datapane account by running `!datapane signup`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Report saved to .//Users/haascp/Documents/GitHub/mocca/notebooks/tutorial_reports/report_peak_db.html. To upload and share your report, create a free Datapane account by running `!datapane signup`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Report saved to .//Users/haascp/Documents/GitHub/mocca/notebooks/tutorial_reports/report_chroms.html. To upload and share your report, create a free Datapane account by running `!datapane signup`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No chromatograms given or all chromatograms are good data!\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Report saved to .//Users/haascp/Documents/GitHub/mocca/notebooks/tutorial_reports/report_runs.html. To upload and share your report, create a free Datapane account by running `!datapane signup`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No PARAFAC models were found in the given datasets.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Report saved to .//Users/haascp/Documents/GitHub/mocca/notebooks/tutorial_reports/report_quali_comp_db.html. To upload and share your report, create a free Datapane account by running `!datapane signup`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Report saved to .//Users/haascp/Documents/GitHub/mocca/notebooks/tutorial_reports/report_quant_comp_db.html. To upload and share your report, create a free Datapane account by running `!datapane signup`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "camp.generate_reports(test_report_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e1b285-98fa-45ef-9808-a3dd9f89931d",
   "metadata": {},
   "source": [
    "### Results extraction in Python environment\n",
    "\n",
    "In the following sections, all relevant data are presented first in the Pythonic form, i.e., in which object the information is stored. Then, the corresponding report will be created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bba460-0c7f-4b3d-9285-6f4a16ebccc7",
   "metadata": {},
   "source": [
    "### User input\n",
    "\n",
    "Let's first look at the stored user input and the corresponding report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38f9dbe9-af68-4c38-ae13-207d106aa0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HplcInput(path='/Users/haascp/Documents/GitHub/mocca/notebooks/tutorial_data/2022-01-26_19-48-52_ba_1.D', gradient=Gradient(/Users/haascp/Documents/GitHub/mocca/notebooks/tutorial_data/2022-01-26_19-43-27_gradient.D), compound=Compound(key='benzaldehyde', conc=1, is_solvent=False, is_istd=False), istd=None, processed=True, custom_data=None), HplcInput(path='/Users/haascp/Documents/GitHub/mocca/notebooks/tutorial_data/2022-01-26_20-00-51_ba_0.5.D', gradient=Gradient(/Users/haascp/Documents/GitHub/mocca/notebooks/tutorial_data/2022-01-26_19-43-27_gradient.D), compound=None, istd=None, processed=True, custom_data=None)]\n"
     ]
    }
   ],
   "source": [
    "# where to find in environment\n",
    "print(camp.hplc_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e514f1-1e3b-4e8a-97ab-9274bb4a094f",
   "metadata": {},
   "source": [
    "### Gradients\n",
    "\n",
    "Gradient objects can be found as attributes in the above mentioned HplcInput objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f2d8cb-caf0-4d64-a518-5359643a495b",
   "metadata": {},
   "source": [
    "### Chromatograms\n",
    "\n",
    "This is the main results source which you find in the chroms attribute of the campaign. The chromatograms have several attributes like experiment (the HPLC input), peaks (all picked and processed peaks of the chromatogram), dataset (the HPLC–DAD raw data object) and a boolean value in bad_data which indicates if the analysis has found some critical problem with the dataset (e.g. the user gives an internal standard but the corrsponding peak was not found)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24146dc7-b12a-4b13-b2cd-f31074509946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chroms attribute:\n",
      "[<mocca.chromatogram.model.Chromatogram object at 0x7fa230d9fb80>, <mocca.chromatogram.model.Chromatogram object at 0x7fa230eb7d60>]\n",
      "\n",
      "User input for the chrom:\n",
      "HplcInput(path='/Users/haascp/Documents/GitHub/mocca/notebooks/tutorial_data/2022-01-26_19-48-52_ba_1.D', gradient=Gradient(/Users/haascp/Documents/GitHub/mocca/notebooks/tutorial_data/2022-01-26_19-43-27_gradient.D), compound=Compound(key='benzaldehyde', conc=1, is_solvent=False, is_istd=False), istd=None, processed=True, custom_data=None)\n",
      "\n",
      "Found peaks:\n",
      "[ProcessedPeak(left=1360, right=1399, maximum=1374, offset=0, dataset=<class 'mocca.dad_data.models.CompoundData'>, idx=1, saturation=False, pure=True, integral=9543.834340662826, istd=[], compound_id='benzaldehyde_impurity_1', concentration=None, is_compound=False), ProcessedPeak(left=1437, right=1521, maximum=1471, offset=0, dataset=<class 'mocca.dad_data.models.CompoundData'>, idx=2, saturation=False, pure=True, integral=260967.44102500076, istd=[], compound_id='benzaldehyde', concentration=1, is_compound=True)]\n",
      "\n",
      "Dataset:\n",
      "CompoundData(hplc_system_tag='chemstation', path='/Users/haascp/Documents/GitHub/mocca/notebooks/tutorial_data/2022-01-26_19-48-52_ba_1.D', data=array([[-1.37719602e+00, -1.34173408e+00, -1.25293882e+00, ...,\n",
      "         2.96112510e+00,  3.05941358e+00,  3.30436780e+00],\n",
      "       [-1.31121424e+00, -1.24186012e+00, -1.18583934e+00, ...,\n",
      "         3.21473227e+00,  3.22471678e+00,  3.38136696e+00],\n",
      "       [-1.01989447e+00, -9.50662806e-01, -8.61431152e-01, ...,\n",
      "         3.51669975e+00,  3.57371566e+00,  3.81073049e+00],\n",
      "       ...,\n",
      "       [-1.55064475e-02,  1.80091400e-02,  4.85805505e-03, ...,\n",
      "        -2.75406104e-02, -4.73490170e-02, -5.38241202e-02],\n",
      "       [-3.76238333e-02, -3.76443072e-02, -1.76647913e-02, ...,\n",
      "         3.66340685e-03,  5.01303544e-02,  9.93074021e-03],\n",
      "       [ 7.18502180e-02,  1.38259622e-01,  1.58002354e-01, ...,\n",
      "        -4.02339693e-03, -5.69526690e-02,  3.45104502e-03]]), time=array([1.59883721e-03, 3.19767442e-03, 4.79651163e-03, ...,\n",
      "       3.98430233e+00, 3.98590116e+00, 3.98750000e+00]), wavelength=array([215., 216., 217., 218., 219., 220., 221., 222., 223., 224., 225.,\n",
      "       226., 227., 228., 229., 230., 231., 232., 233., 234., 235., 236.,\n",
      "       237., 238., 239., 240., 241., 242., 243., 244., 245., 246., 247.,\n",
      "       248., 249., 250., 251., 252., 253., 254., 255., 256., 257., 258.,\n",
      "       259., 260., 261., 262., 263., 264., 265., 266., 267., 268., 269.,\n",
      "       270., 271., 272., 273., 274., 275., 276., 277., 278., 279., 280.,\n",
      "       281., 282., 283., 284., 285., 286., 287., 288., 289., 290., 291.,\n",
      "       292., 293., 294., 295., 296., 297., 298., 299., 300., 301., 302.,\n",
      "       303., 304., 305., 306., 307., 308., 309., 310., 311., 312., 313.,\n",
      "       314., 315., 316., 317., 318., 319., 320., 321., 322., 323., 324.,\n",
      "       325., 326., 327., 328., 329., 330., 331., 332., 333., 334., 335.,\n",
      "       336., 337., 338., 339., 340., 341., 342., 343., 344., 345., 346.,\n",
      "       347., 348., 349., 350., 351., 352., 353., 354., 355., 356., 357.,\n",
      "       358., 359., 360., 361., 362., 363., 364., 365., 366., 367., 368.,\n",
      "       369., 370., 371., 372., 373., 374., 375., 376., 377., 378., 379.,\n",
      "       380., 381., 382., 383., 384., 385., 386., 387., 388., 389., 390.,\n",
      "       391., 392., 393., 394., 395., 396., 397., 398., 399., 400., 401.,\n",
      "       402., 403., 404., 405., 406., 407., 408., 409., 410., 411., 412.,\n",
      "       413., 414., 415., 416., 417., 418., 419., 420., 421., 422., 423.,\n",
      "       424., 425., 426., 427., 428., 429., 430., 431., 432., 433., 434.,\n",
      "       435., 436., 437., 438., 439., 440., 441., 442., 443., 444., 445.,\n",
      "       446., 447., 448., 449.]), warnings=[])\n",
      "\n",
      "Bad Data:\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# where to find in environment\n",
    "print(f\"Chroms attribute:\\n{camp.chroms}\\n\")\n",
    "print(f\"User input for the chrom:\\n{camp.chroms[0].experiment}\\n\")  # hplc_input is labelled \"experiment\" in the backend\n",
    "print(f\"Found peaks:\\n{camp.chroms[0].peaks}\\n\")\n",
    "print(f\"Dataset:\\n{camp.chroms[0].dataset}\\n\")\n",
    "print(f\"Bad Data:\\n{camp.chroms[0].bad_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3e7126-e48e-4cd5-b097-27b2754fd382",
   "metadata": {},
   "source": [
    "### Peak database\n",
    "\n",
    "In this attribute, all processed peaks of all chromatograms in the campaign are stored. This database is used to create the qualitative and the quantitative component databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "300c86a3-a527-4e5b-a8c8-19169637e1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database object:\n",
      "<mocca.peak.database.PeakDatabase object at 0x7fa230d9feb0>\n",
      "\n",
      "Database entries (peaks):\n",
      "ProcessedPeak(left=1437, right=1521, maximum=1471, offset=0, dataset=<class 'mocca.dad_data.models.CompoundData'>, idx=2, saturation=False, pure=True, integral=260967.44102500076, istd=[], compound_id='benzaldehyde', concentration=1, is_compound=True)\n",
      "ProcessedPeak(left=1360, right=1399, maximum=1374, offset=0, dataset=<class 'mocca.dad_data.models.CompoundData'>, idx=1, saturation=False, pure=True, integral=9543.834340662826, istd=[], compound_id='benzaldehyde_impurity_1', concentration=None, is_compound=False)\n",
      "ProcessedPeak(left=1448, right=1524, maximum=1472, offset=0, dataset=<class 'mocca.dad_data.models.CompoundData'>, idx=1, saturation=False, pure=True, integral=140531.506470337, istd=[], compound_id='benzaldehyde', concentration=0.5220528115580446, is_compound=False)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Database object:\\n{camp.peak_db}\\n\")\n",
    "\n",
    "print(\"Database entries (peaks):\")\n",
    "for peak in camp.peak_db:\n",
    "    print(peak)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187fff2f-6b85-4707-96d8-137cbcd9887f",
   "metadata": {},
   "source": [
    "### Qualitative component database\n",
    "\n",
    "In this database, the components (created from the signals of the same compound over multiple chromatograms) contain the information needed for peak assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c069c40e-915a-407a-9b85-ff8c76511c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database object:\n",
      "<mocca.components.databases.QualiComponentDatabase object at 0x7fa230db87f0>\n",
      "\n",
      "Database entries (qualitative components):\n",
      "QualiComponent(compound_id='benzaldehyde', left=1442, right=1522, maximum=1472, offset=0, spectrum=<class 'list'>, spectrum_max=[32, 67], created_from=[ProcessedPeak(left=1437, right=1521, maximum=1471, offset=0, dataset=<class 'mocca.dad_data.models.CompoundData'>, idx=2, saturation=False, pure=True, integral=260967.44102500076, istd=[], compound_id='benzaldehyde', concentration=1, is_compound=True)])\n",
      "QualiComponent(compound_id='benzaldehyde_impurity_1', left=1360, right=1399, maximum=1374, offset=0, spectrum=<class 'list'>, spectrum_max=[14, 36, 59, 57, 55, 61, 46, 66, 48, 44, 53, 40, 51], created_from=[ProcessedPeak(left=1360, right=1399, maximum=1374, offset=0, dataset=<class 'mocca.dad_data.models.CompoundData'>, idx=1, saturation=False, pure=True, integral=9543.834340662826, istd=[], compound_id='benzaldehyde_impurity_1', concentration=None, is_compound=False)])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Database object:\\n{camp.quali_comp_db}\\n\")\n",
    "\n",
    "print(\"Database entries (qualitative components):\")\n",
    "for comp in camp.quali_comp_db:\n",
    "    print(comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa99cd1-4007-44de-8dc3-4dce061eace7",
   "metadata": {},
   "source": [
    "### Quantitative component database\n",
    "\n",
    "In this database, the components (created from the signals of the same compound over multiple chromatograms) contain the information needed for peak quantification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb2de703-b8f4-4f6b-9228-483fc0aa5b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database object:\n",
      "<mocca.components.databases.QuantComponentDatabase object at 0x7fa230db83d0>\n",
      "\n",
      "Database entries (quantitative components):\n",
      "QuantComponent(compound_id='benzaldehyde', integrate_wl_idx=32, calib_factors={'absolute': 8241.430639716607}, calib_data={'absolute': [(1, 8241.430639716607)]}, calib_scores={'absolute': nan}, created_from=[ProcessedPeak(left=1437, right=1521, maximum=1471, offset=0, dataset=<class 'mocca.dad_data.models.CompoundData'>, idx=2, saturation=False, pure=True, integral=260967.44102500076, istd=[], compound_id='benzaldehyde', concentration=1, is_compound=True)])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Database object:\\n{camp.quant_comp_db}\\n\")\n",
    "\n",
    "print(\"Database entries (quantitative components):\")\n",
    "for comp in camp.quant_comp_db:\n",
    "    print(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bba3a99-0966-44a5-92f1-80c3d159e72e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mocca-dev",
   "language": "python",
   "name": "mocca-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
